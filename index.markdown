---
# Feel free to add content and custom Front Matter to this file.
# To modify the layout, see https://jekyllrb.com/docs/themes/#overriding-theme-defaults

layout: default
---

## About Me
I am a third-year Cognitive Science Ph.D. student at Stony Brook University working with [Dr. Gregory Zelinsky](https://www.stonybrook.edu/commcms/psychology/faculty/faculty_profiles/gzelinsky). 

My research interests are in the intersection of multimodal generative modelling and visual perception, focusing on building brain-inspired neural network architectures and generating human-aligned visual content.

I am always interested in research collaborations. Feel free to schedule a 30-min meeting on [GCal](https://calendar.app.google/Xixk6ep28USu5AVx9) if you are interested in collaborating or discussing research ideas.

## Recent News
- Paper accepted at ICLR 2026!
- Short paper accepted at CCN 2025!
- Talk Presentation accepted at VSS 2025!
- Poster accepted at OPAM 2024 (also won Best Poster Award!)
- Short paper accepted at CCN 2024!
- Talk Presentation accepted at VSS 2024!
- Paper accepted at NeurIPS 2023!

## Select Publications and Talks
- **[Generating metamers of human scene understanding](https://arxiv.org/abs/2601.11675)**  
  **Ritik Raina**, Abe Leite, Alexandros Graikos, Seoyoung Ahn, Dimitris Samaras, Gregory Zelinsky  
  *ICLR 2026*

- **[Seen2Scene: a generative model of fixation-by-fixation scene understanding](https://2025.ccneuro.org/abstract_pdf/Raina_2025_Seen2Scene_generative_model_fixation-by-fixation_scene_understanding.pdf)**  
  **Ritik Raina**, Abe Leite, Alexandros Graikos, Seoyoung Ahn, Gregory Zelinsky  
  *CCN 2025*

- **[Modeling human scene understanding fixation-by-fixation using generative models](https://jov.arvojournals.org/article.aspx?articleid=2810134)**  
  **Ritik Raina**, Alexandros Graikos, Abe Leite, Seoyoung Ahn, Gregory Zelinsky  
  *VSS 2025*

- **[Framework for a Generative Multi-modal model of Embodied Thought](https://2024.ccneuro.org/pdf/634_Paper_authored_CCN_2024_Zelinsky-FINAL.pdf)**  
  Gregory Zelinsky, **Ritik Raina**, Abe Leite, Seoyoung Ahn  
  *CCN 2024*

- **[Generating objects in peripheral vision using attention-guided diffusion models](https://jov.arvojournals.org/article.aspx?articleid=2801786)**  
  **Ritik Raina**, Seoyoung Ahn, Gregory Zelinsky  
  *VSS 2024*

- **[Adaptive recurrent vision performs zero-shot computation scaling to unseen difficulty levels](https://arxiv.org/abs/2311.06964)**  
  Vijay Veerabadran, Srinivas Ravishankar, Yuan Tang, **Ritik Raina**, Virginia R. de Sa  
  *NeurIPS 2023*

- **[Cortically motivated recurrence enables task extrapolation](https://drive.google.com/file/d/1Onf04NMijI0RowD-QCPTJGl9vrsnP38E/view)**  
  Vijay Veerabadran, Yuan Tang, **Ritik Raina**, Virginia R. de Sa  
  *COSYNE 2023*

- **[Exploring Biases in Facial Expression Analysis using Synthetic Faces](https://drive.google.com/file/d/1Onf04NMijI0RowD-QCPTJGl9vrsnP38E/view)**  
  **Ritik Raina**, Miguel Monares, Mingze Xu, Sarah Fabi, Xiaojing Xu, Lehan Li, Will Sumerfield, Jin Gan, Virginia R. de Sa  
  *NeurIPS SyntheticData4ML Workshop 2022*

- **[Bio-inspired learnable divisive normalization for ANNs](https://openreview.net/pdf?id=-ZOjASLOsrV)**  
  Vijay Veerabadran, **Ritik Raina**, Virginia R. de Sa  
  *NeurIPS SVRHM Workshop 2021*

